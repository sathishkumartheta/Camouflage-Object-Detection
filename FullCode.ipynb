{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import load_dataset\n",
    "from transformers import MaskFormerImageProcessor, MaskFormerForInstanceSegmentation\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME']='EDA.ipynb'\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]='TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (HTTPError), entering retry loop.\n",
      "wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "source": [
    "Logging_Place= 'LOCAL'\n",
    "\n",
    "if Logging_Place == 'LOCAL':\n",
    "    os.environ['WANDB_BASE_URL']=\"http://10.24.1.19:8080\"\n",
    "    os.environ['WANDB_API_KEY']='local-96dd72cbb60b0155149e2f9dc985a636ffa77b28'\n",
    "    ! wandb login --host=http://10.24.1.19:8080\n",
    "\n",
    "elif Logging_Place ==\"CLOUD\":\n",
    "    os.environ['WANDB_BASE_URL']=\"https://api.wandb.ai\"\n",
    "    os.environ['WANDB_API_KEY']='be69ec2b537cb972b0106fabd867f0dc68c4468a'\n",
    "    ! wandb login --host=https://api.wandb.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=Path('COD10K-v2')\n",
    "train_path=data_path / 'Train'\n",
    "test_path= data_path / 'Test'\n",
    "\n",
    "train_images_path= train_path / 'Images/Image'\n",
    "train_labels_path= train_path / 'GT_Objects/GT_Object'\n",
    "\n",
    "test_images_path= test_path / 'Images/Image'\n",
    "test_labels_path= test_path / 'GT_Objects/GT_Object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('COD10K-v2/Train/Images/Image/COD10K-CAM-1-Aquatic-1-BatFish-1.jpg'), WindowsPath('COD10K-v2/Train/Images/Image/COD10K-CAM-1-Aquatic-1-BatFish-3.jpg'), WindowsPath('COD10K-v2/Train/Images/Image/COD10K-CAM-1-Aquatic-1-BatFish-7.jpg'), WindowsPath('COD10K-v2/Train/Images/Image/COD10K-CAM-1-Aquatic-1-BatFish-8.jpg'), WindowsPath('COD10K-v2/Train/Images/Image/COD10K-CAM-1-Aquatic-1-BatFish-9.jpg')]\n",
      "[WindowsPath('COD10K-v2/Train/GT_Objects/GT_Object/COD10K-CAM-1-Aquatic-1-BatFish-1.png'), WindowsPath('COD10K-v2/Train/GT_Objects/GT_Object/COD10K-CAM-1-Aquatic-1-BatFish-3.png'), WindowsPath('COD10K-v2/Train/GT_Objects/GT_Object/COD10K-CAM-1-Aquatic-1-BatFish-7.png'), WindowsPath('COD10K-v2/Train/GT_Objects/GT_Object/COD10K-CAM-1-Aquatic-1-BatFish-8.png'), WindowsPath('COD10K-v2/Train/GT_Objects/GT_Object/COD10K-CAM-1-Aquatic-1-BatFish-9.png')]\n"
     ]
    }
   ],
   "source": [
    "train_images_list=list(train_images_path.glob('*.jpg'))\n",
    "print(train_images_list[0:5])\n",
    "train_labels_list=list(train_labels_path.glob('*.png'))\n",
    "print(train_labels_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Other', 'Aquatic', 'Terrestial', 'Background', 'Amphibian', 'Flying', 'Terrestrial']\n"
     ]
    }
   ],
   "source": [
    "super_classes_list=[ i.stem.split('-')[3] for i in train_images_list]\n",
    "super_classes_list=[*set(super_classes_list)]\n",
    "print(super_classes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lizard', 'Shrimp', 'Beetle', 'Cat', 'Monkey', 'Katydid', 'Sciuridae', 'Sand', 'Sheep', 'Toad', 'Sky', 'Bittern', 'Bug', 'Cheetah', 'Wolf', 'Dragonfly', 'Bird', 'Indoor', 'SeaHorse', 'Grouse', 'Ocean', 'CrocodileFish', 'Flounder', 'Turtle', 'StickInsect', 'Leopard', 'Frog', 'Vegetation', 'Gecko', 'Reccoon', 'Slug', 'Dog', 'LeafySeaDragon', 'StarFish', 'Duck', 'BatFish', 'Frogmouth', 'Mantis', 'Mockingbird', 'ClownFish', 'Fish', 'Deer', 'Octopus', 'Crocodile', 'GhostPipefish', 'Spider', 'Stingaree', 'Ant', 'Cicada', 'Heron', 'Owl', 'Bee', 'Centipede', 'Owlfly', 'Chameleon', 'Other', 'Rabbit', 'Lion', 'Bat', 'Pipefish', 'FrogFish', 'Tiger', 'Butterfly', 'Grasshopper', 'ScorpionFish', 'Kangaroo', 'Worm', 'Caterpillar', 'Moth', 'Snake', 'Giraffe', 'Pagurian', 'Crab', 'Human']\n"
     ]
    }
   ],
   "source": [
    "index=5\n",
    "sub_classes_list=[]\n",
    "for i in train_images_list:\n",
    "    split_path=i.stem.split('-')\n",
    "    count=len(split_path)\n",
    "    if (index<count):\n",
    "        sub_classes_list.append(split_path[index])\n",
    "sub_classes_list=[*set(sub_classes_list)]\n",
    "print(sub_classes_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####    Setting up dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamouflageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_directory:str,\n",
    "        gt_directory:str,\n",
    "        transform=None\n",
    "    ):\n",
    "        self.image_directory=image_directory\n",
    "        self.gt_directory=gt_directory\n",
    "        self.transforms = transform\n",
    "        self.image_list=list(self.image_directory.glob('*.jpg'))\n",
    "        self.gt_list=list(self.gt_directory.glob('*.png'))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img=Image.open(self.image_list[idx])\n",
    "        mask=Image.open(self.gt_list[idx])\n",
    "        self.transforms = transforms.Compose([transforms.ToTensor()])\n",
    "        img=self.transforms(img)\n",
    "        mask=self.transforms(mask)     \n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=CamouflageDataset(image_directory=train_images_path,\n",
    "                                gt_directory=train_labels_path\n",
    "                                )\n",
    "test_dataset=CamouflageDataset(image_directory=test_images_path,\n",
    "                                gt_directory=test_labels_path\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(train_dataset,batch_size=1, shuffle=True)\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([1, 3, 533, 800])\n",
      "Labels batch shape: torch.Size([1, 1, 533, 800])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(test_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerFeatureExtractor\n",
    "from transformers import SegformerForSemanticSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at mit-b0 and are newly initialized: ['decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_fuse.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.1.proj.weight', 'decode_head.classifier.weight', 'decode_head.batch_norm.bias', 'decode_head.classifier.bias', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.2.proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SegformerForSemanticSegmentation.from_pretrained(\"mit-b0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                                                      Param #\n",
       "====================================================================================================\n",
       "SegformerForSemanticSegmentation                                            --\n",
       "├─SegformerModel: 1-1                                                       --\n",
       "│    └─SegformerEncoder: 2-1                                                --\n",
       "│    │    └─ModuleList: 3-1                                                 485,472\n",
       "│    │    └─ModuleList: 3-2                                                 2,832,896\n",
       "│    │    └─ModuleList: 3-3                                                 1,024\n",
       "├─SegformerDecodeHead: 1-2                                                  --\n",
       "│    └─ModuleList: 2-2                                                      --\n",
       "│    │    └─SegformerMLP: 3-4                                               8,448\n",
       "│    │    └─SegformerMLP: 3-5                                               16,640\n",
       "│    │    └─SegformerMLP: 3-6                                               41,216\n",
       "│    │    └─SegformerMLP: 3-7                                               65,792\n",
       "│    └─Conv2d: 2-3                                                          262,144\n",
       "│    └─BatchNorm2d: 2-4                                                     512\n",
       "│    └─ReLU: 2-5                                                            --\n",
       "│    └─Dropout: 2-6                                                         --\n",
       "│    └─Conv2d: 2-7                                                          257,000\n",
       "====================================================================================================\n",
       "Total params: 3,971,144\n",
       "Trainable params: 3,971,144\n",
       "Non-trainable params: 0\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CamoTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54b1efcbe9702cb5a8b4c38cb931ca9223af49f11d78bd3b48c2307ccff1ccd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
