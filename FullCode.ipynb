{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import load_dataset\n",
    "from transformers import MaskFormerImageProcessor, MaskFormerForInstanceSegmentation\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import torchvision.models as models\n",
    "from tqdm.auto import tqdm\n",
    "import torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME']='EDA.ipynb'\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]='TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (HTTPError), entering retry loop.\n",
      "wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "source": [
    "Logging_Place= 'LOCAL'\n",
    "\n",
    "if Logging_Place == 'LOCAL':\n",
    "    os.environ['WANDB_BASE_URL']=\"http://10.24.1.19:8080\"\n",
    "    os.environ['WANDB_API_KEY']='local-96dd72cbb60b0155149e2f9dc985a636ffa77b28'\n",
    "    ! wandb login --host=http://10.24.1.19:8080\n",
    "\n",
    "elif Logging_Place ==\"CLOUD\":\n",
    "    os.environ['WANDB_BASE_URL']=\"https://api.wandb.ai\"\n",
    "    os.environ['WANDB_API_KEY']='be69ec2b537cb972b0106fabd867f0dc68c4468a'\n",
    "    ! wandb login --host=https://api.wandb.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=Path('COD10K-v2')\n",
    "train_path=data_path / 'Train'\n",
    "test_path= data_path / 'Test'\n",
    "\n",
    "train_images_path= train_path / 'Images/Image'\n",
    "train_labels_path= train_path / 'GT_Objects/GT_Object'\n",
    "\n",
    "test_images_path= test_path / 'Images/Image'\n",
    "test_labels_path= test_path / 'GT_Objects/GT_Object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('COD10K-v2/Train/Images/Image/COD10K-CAM-1-Aquatic-1-BatFish-1.jpg'), WindowsPath('COD10K-v2/Train/Images/Image/COD10K-CAM-1-Aquatic-1-BatFish-3.jpg'), WindowsPath('COD10K-v2/Train/Images/Image/COD10K-CAM-1-Aquatic-1-BatFish-7.jpg'), WindowsPath('COD10K-v2/Train/Images/Image/COD10K-CAM-1-Aquatic-1-BatFish-8.jpg'), WindowsPath('COD10K-v2/Train/Images/Image/COD10K-CAM-1-Aquatic-1-BatFish-9.jpg')]\n",
      "[WindowsPath('COD10K-v2/Train/GT_Objects/GT_Object/COD10K-CAM-1-Aquatic-1-BatFish-1.png'), WindowsPath('COD10K-v2/Train/GT_Objects/GT_Object/COD10K-CAM-1-Aquatic-1-BatFish-3.png'), WindowsPath('COD10K-v2/Train/GT_Objects/GT_Object/COD10K-CAM-1-Aquatic-1-BatFish-7.png'), WindowsPath('COD10K-v2/Train/GT_Objects/GT_Object/COD10K-CAM-1-Aquatic-1-BatFish-8.png'), WindowsPath('COD10K-v2/Train/GT_Objects/GT_Object/COD10K-CAM-1-Aquatic-1-BatFish-9.png')]\n"
     ]
    }
   ],
   "source": [
    "train_images_list=list(train_images_path.glob('*.jpg'))\n",
    "print(train_images_list[0:5])\n",
    "train_labels_list=list(train_labels_path.glob('*.png'))\n",
    "print(train_labels_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aquatic', 'Terrestrial', 'Terrestial', 'Amphibian', 'Flying', 'Background', 'Other']\n"
     ]
    }
   ],
   "source": [
    "super_classes_list=[ i.stem.split('-')[3] for i in train_images_list]\n",
    "super_classes_list=[*set(super_classes_list)]\n",
    "print(super_classes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pipefish', 'Caterpillar', 'Deer', 'SeaHorse', 'Mockingbird', 'Owl', 'Stingaree', 'Centipede', 'GhostPipefish', 'Bug', 'Flounder', 'Shrimp', 'Mantis', 'StarFish', 'Dog', 'Giraffe', 'FrogFish', 'Kangaroo', 'Fish', 'Turtle', 'Reccoon', 'Butterfly', 'Leopard', 'Indoor', 'Human', 'Grasshopper', 'Spider', 'Toad', 'Dragonfly', 'Bittern', 'Owlfly', 'Crab', 'Crocodile', 'Sky', 'Heron', 'ClownFish', 'Lizard', 'Lion', 'Snake', 'StickInsect', 'Gecko', 'Wolf', 'Sheep', 'Monkey', 'Beetle', 'Vegetation', 'Octopus', 'Katydid', 'Frog', 'Other', 'Cat', 'Sciuridae', 'Bee', 'BatFish', 'CrocodileFish', 'Cheetah', 'Cicada', 'Ocean', 'Pagurian', 'ScorpionFish', 'Bird', 'Moth', 'Sand', 'Bat', 'Ant', 'Duck', 'Chameleon', 'Worm', 'Tiger', 'LeafySeaDragon', 'Slug', 'Grouse', 'Frogmouth', 'Rabbit']\n"
     ]
    }
   ],
   "source": [
    "index=5\n",
    "sub_classes_list=[]\n",
    "for i in train_images_list:\n",
    "    split_path=i.stem.split('-')\n",
    "    count=len(split_path)\n",
    "    if (index<count):\n",
    "        sub_classes_list.append(split_path[index])\n",
    "sub_classes_list=[*set(sub_classes_list)]\n",
    "print(sub_classes_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####    Setting up dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamouflageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str,\n",
    "        feature_extractor,\n",
    "        split:str\n",
    "    ):\n",
    "        self.root_dir=Path(root_dir)\n",
    "        if split==\"train\":\n",
    "            self.data_dir=self.root_dir / \"Train\"\n",
    "        elif split==\"test\":\n",
    "            self.data_dir=self.root_dir /\"Test\"\n",
    "\n",
    "        self.image_dir=self.data_dir / \"Images/Image\"\n",
    "        self.gt_dir=self.data_dir / \"GT_objects/GT_Object\"\n",
    "\n",
    "        self.feature_extractor=feature_extractor\n",
    "\n",
    "        self.unsorted_image_list= list(self.image_dir.glob('*.jpg'))\n",
    "        self.sorted_image_list=sorted(self.unsorted_image_list)\n",
    "\n",
    "        self.unsorted_gt_list=list(self.gt_dir.glob('*.png'))\n",
    "        self.sorted_gt_list=sorted(self.unsorted_gt_list)\n",
    "\n",
    "        #print(self.sorted_image_list[0:5])\n",
    "        #print(self.sorted_gt_list[0:5])\n",
    "\n",
    "        assert (len(self.sorted_gt_list)==len(self.sorted_image_list)), \"Number of images and ground truths must be same\"\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img=Image.open(self.sorted_image_list[idx])\n",
    "        gt=Image.open(self.sorted_gt_list[idx])\n",
    "\n",
    "        encoded_input=self.feature_extractor(img,gt,return_tensors=\"pt\")\n",
    "\n",
    "        for k,v in encoded_input.items():\n",
    "            encoded_input[k].squeeze_()\n",
    "        return encoded_input\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sorted_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor=SegformerImageProcessor()\n",
    "train_dataset=CamouflageDataset(root_dir='COD10K-v2', feature_extractor= feature_extractor, split=\"train\")\n",
    "test_dataset=CamouflageDataset(root_dir='COD10K-v2', feature_extractor= feature_extractor, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n",
      "torch.Size([512, 512])\n"
     ]
    }
   ],
   "source": [
    "encoded_input=train_dataset[0]\n",
    "print(encoded_input[\"pixel_values\"].shape)\n",
    "print(encoded_input[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(train_dataset,batch_size=1, shuffle=True)\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512, 512])\n",
      "torch.Size([1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "batch=next(iter(train_dataloader))\n",
    "print(batch[\"pixel_values\"].shape)\n",
    "print(batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label=json.load(open('COD10K-v2.json', \"r\"))\n",
    "id2label = {int(k): v for k, v in id2label.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'background', 1: 'camouflage object'}\n",
      "{'background': 0, 'camouflage object': 1}\n"
     ]
    }
   ],
   "source": [
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at mit-b0 and are newly initialized: ['decode_head.linear_c.3.proj.weight', 'decode_head.classifier.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.linear_fuse.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.1.proj.bias', 'decode_head.classifier.bias', 'decode_head.batch_norm.bias', 'decode_head.batch_norm.running_mean', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.2.proj.weight', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.linear_c.2.proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SegformerForSemanticSegmentation.from_pretrained(\"mit-b0\",\n",
    "                                                         num_labels=2, \n",
    "                                                         id2label=id2label, \n",
    "                                                         label2id=label2id\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CamoTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54b1efcbe9702cb5a8b4c38cb931ca9223af49f11d78bd3b48c2307ccff1ccd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
